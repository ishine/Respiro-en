{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Started (detailed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from modules import feature_extractor, DetectionNet, BreathDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model loading\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DetectionNet().to(device)\n",
    "checkpoint = torch.load(\"respiro-en.pt\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_path = \"samples/train-clean-100_19_198_000010_000003.wav\"\n",
    "#wav_path = \"samples/train-clean-360_14_208_000001_000000.wav\"\n",
    "#wav_path = \"samples/train-other-500_20_205_000002_000002.wav\"\n",
    "wav, sr = librosa.load(wav_path, sr=16000)\n",
    "feature, length = feature_extractor(wav)\n",
    "feature, length = feature.to(device), length.to(device)\n",
    "output = model(feature, length)\n",
    "\n",
    "# 0.064 is the threshold obtained from our validation set\n",
    "# You can try more strict thresholds like 0.5 or 0.9\n",
    "threshold = 0.064\n",
    "\n",
    "# min_length: length threshold to avoid too short detected breath, which tends to be the end part of speech\n",
    "# default: 20 ms\n",
    "min_length = 20\n",
    "\n",
    "prediction = (output[0] > 0.064).nonzero().squeeze().tolist()\n",
    "if isinstance(prediction, list) and len(prediction)>1:\n",
    "    diffs = np.diff(prediction)\n",
    "    splits = np.where(diffs != 1)[0] + 1\n",
    "    splits = np.split(prediction, splits)\n",
    "    splits = list(filter(lambda split: len(split)>min_length, splits))\n",
    "    if len(splits)>1:\n",
    "        for split in splits:\n",
    "            print(split)\n",
    "# The segments of breath are printed\n",
    "# 229 means 229 ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = splits[1][0]\n",
    "end = splits[1][-1]\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(data=wav[int((start*0.01)*sr):int((end*0.01)*sr)], rate=sr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Started (quick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from modules import DetectionNet, BreathDetector\n",
    "\n",
    "# model loading\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DetectionNet().to(device)\n",
    "checkpoint = torch.load(\"respiro-en.pt\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.eval()\n",
    "\n",
    "detector = BreathDetector(model) # Args: model, device=None\n",
    "\n",
    "tree = detector(\"train-clean-100_19_198_000010_000003.wav\") # Args: wav_path, threshold=0.064, min_length=20\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree[2.6:5.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(tree))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
